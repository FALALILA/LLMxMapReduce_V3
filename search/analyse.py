import os
import json
import logging
import asyncio
import time
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from request.wrapper import RequestWrapper
from .llm_search_host import LLMSearchHost
    
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AnalyseInterface:
    def __init__(self,
                 base_dir: str = "new/test",
                 config_path: Optional[str] = None):

        self.base_dir = Path(base_dir)
        self.config_path = config_path
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.config_dir = self.base_dir / "config"
        self.config_dir.mkdir(exist_ok=True)

        # é¦–å…ˆåŠ è½½ç¯å¢ƒé…ç½®
        self._load_environment_config()

        # ç¡®ä¿env_configå·²è®¾ç½®
        if not hasattr(self, 'env_config') or self.env_config is None:
            logger.error("env_config not properly loaded! Configuration file is required")
            raise FileNotFoundError("Configuration file config/unified_config.json is required but not found or invalid")

        # ä»é…ç½®ä¸­è·å–å‚æ•°
        self.max_interaction_rounds = self.env_config.get("analyse_settings", {}).get("max_interaction_rounds", 3)
        self.llm_model = self.env_config.get("models", {}).get("default_model", "gemini-2.5-flash")
        self.llm_infer_type = self.env_config.get("models", {}).get("default_infer_type", "OpenAI")

        # åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
        self.search_memory = []  # å­˜å‚¨æœç´¢è¿‡ç¨‹çš„è®°å¿†
        self.conversation_history = []  # å­˜å‚¨å®Œæ•´çš„å¯¹è¯å†å²

        # åˆå§‹åŒ–LLMæœç´¢å®¿ä¸»
        self.llm_search_host = LLMSearchHost()

        # åˆå§‹åŒ–loggerï¼ˆä¿®å¤Windowsç¼–ç é—®é¢˜ï¼‰
        self.logger = logging.getLogger(__name__)

        # ç¡®ä¿loggerä½¿ç”¨UTF-8ç¼–ç ï¼Œé¿å…Windows GBKç¼–ç é—®é¢˜
        for handler in logging.root.handlers:
            if hasattr(handler, 'stream') and hasattr(handler.stream, 'reconfigure'):
                try:
                    handler.stream.reconfigure(encoding='utf-8')
                except:
                    pass

# MemoryåŠŸèƒ½å·²ç§»é™¤

        # åˆå§‹åŒ–ç»„ä»¶ï¼ˆåœ¨åŠ è½½é…ç½®ä¹‹åï¼‰
        self._init_llm_components()

        self._load_config()





# _clear_memory_on_initæ–¹æ³•å·²ç§»é™¤

    async def cleanup(self):
        """
        æ¸…ç†èµ„æºï¼Œå…³é—­è¿æ¥
        """
        try:
            if hasattr(self, 'llm_search_host') and self.llm_search_host:
                await self.llm_search_host.disconnect()
            self.logger.info("èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            self.logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")

    def _load_environment_config(self):
        """åŠ è½½ç¯å¢ƒé…ç½®æ–‡ä»¶"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„ç»Ÿä¸€é…ç½®æ–‡ä»¶è·¯å¾„
            config_paths = [
                "new/config/unified_config.json",
                "config/unified_config.json",
                os.path.join(os.path.dirname(__file__), "..", "..", "config", "unified_config.json")
            ]

            for config_path in config_paths:
                if os.path.exists(config_path):
                    with open(config_path, 'r', encoding='utf-8') as f:
                        self.env_config = json.load(f)
                    logger.info(f"Environment config loaded from: {config_path}")

                    # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ç¡®ä¿API keyæ­£ç¡®ä¼ é€’
                    self._set_environment_variables()
                    return

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼ŒæŠ›å‡ºé”™è¯¯
            logger.error("Environment config file not found! Please ensure config/unified_config.json exists")
            raise FileNotFoundError("Configuration file config/unified_config.json is required but not found")
        except Exception as e:
            logger.error(f"Failed to load environment config: {e}")
            self.env_config = {}

    def _set_environment_variables(self):
        """è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿API keyæ­£ç¡®ä¼ é€’"""
        try:
            api_keys = self.env_config.get("api_keys", {})

            # è®¾ç½®OpenAI APIé…ç½®
            openai_config = api_keys.get("openai", {})
            if openai_config.get("api_key"):
                os.environ["OPENAI_API_KEY"] = openai_config["api_key"]
                logger.info("âœ… OPENAI_API_KEY å·²è®¾ç½®")
            if openai_config.get("base_url"):
                os.environ["OPENAI_BASE_URL"] = openai_config["base_url"]
                logger.info("âœ… OPENAI_BASE_URL å·²è®¾ç½®")

            # è®¾ç½®æœç´¢å¼•æ“APIå¯†é’¥
            search_engines = api_keys.get("search_engines", {})
            if search_engines.get("serpapi_key"):
                os.environ["SERPAPI_KEY"] = search_engines["serpapi_key"]
                logger.info(f"âœ… SERPAPI_KEY å·²è®¾ç½®: {search_engines['serpapi_key'][:10]}...")

            if search_engines.get("bing_subscription_key"):
                os.environ["BING_SEARCH_V7_SUBSCRIPTION_KEY"] = search_engines["bing_subscription_key"]
                logger.info("âœ… BING_SEARCH_V7_SUBSCRIPTION_KEY å·²è®¾ç½®")

        except Exception as e:
            logger.error(f"Failed to set environment variables: {e}")

        logger.info(f"AnalyseInterface initialized:")
        logger.info(f"  - Base directory: {self.base_dir}")
        logger.info(f"  - Max interaction rounds: {self.max_interaction_rounds}")
        logger.info(f"  - LLM model: {self.llm_model}")
        logger.info(f"  - Search engine: MCP Client")

    def _init_llm_components(self):
        try:
            self.llm_wrapper = RequestWrapper(
                model=self.llm_model,
                infer_type=self.llm_infer_type
            )
            logger.info("LLM wrapper initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize LLM wrapper: {e}")
            raise









    def _format_available_tools(self, tools: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯ç”¨å·¥å…·ä¿¡æ¯"""
        formatted = []
        for tool in tools:
            name = tool.get("name", "")
            description = tool.get("description", "")

            # æ ¼å¼åŒ–è¾“å…¥å‚æ•°
            input_schema = tool.get("inputSchema", {})
            properties = input_schema.get("properties", {})
            required = input_schema.get("required", [])

            params_info = []
            for prop, prop_info in properties.items():
                prop_type = prop_info.get("type", "string")
                prop_desc = prop_info.get("description", "")
                is_required = prop in required
                req_marker = " (å¿…éœ€)" if is_required else " (å¯é€‰)"
                params_info.append(f"{prop}: {prop_type}{req_marker} - {prop_desc}")

            params_str = "; ".join(params_info) if params_info else "æ— å‚æ•°"
            formatted.append(f"- {name}: {description}\n  å‚æ•°: {params_str}")

        return "\n".join(formatted)

    async def analyse(self, topic: str, description: Optional[str] = None,
                      top_n: int = 20) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå®Œæ•´çš„æ–‡çŒ®åˆ†æå·¥ä½œæµ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è°ƒç”¨llm_search_host

        Args:
            topic: ç ”ç©¶ä¸»é¢˜
            description: ä¸»é¢˜æè¿°
            top_n: è¿”å›ç»“æœæ•°é‡
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        logger.info(f"Starting literature analysis for topic: '{topic}'")

        # è®°å¿†åˆå§‹åŒ–
        self.conversation_history.clear()
        logger.info("=== è®°å¿†åˆå§‹åŒ–å®Œæˆ ===")

        try:
            # ç¬¬ä¸€è½®äº¤äº’ï¼šä¸»é¢˜æ‰©å†™
            logger.info("=== ç¬¬ä¸€è½®äº¤äº’ï¼šä¸»é¢˜æ‰©å†™ ===")
            user_msg_1 = f"è¯·æ‰©å†™ä¸»é¢˜ï¼š{topic}ã€‚åŸå§‹æè¿°ï¼š{description or 'æ— '}"
            expanded_topic = await self._llm_interaction_round_1(user_msg_1)
            logger.info(f"ä¸»é¢˜æ‰©å†™å®Œæˆ: {expanded_topic[:100]}...")

            # ç¬¬äºŒè½®ï¼šç›´æ¥æ‰§è¡Œæ–‡çŒ®æœç´¢
            logger.info("=== ç¬¬äºŒè½®ï¼šæ‰§è¡Œæ–‡çŒ®æœç´¢ ===")

            # ä½¿ç”¨llm_search_hostæ‰§è¡Œå®Œæ•´çš„æœç´¢æµç¨‹
            results = await self.llm_search_host.search_literature(
                topic=topic,
                description=expanded_topic,
                top_n=top_n
            )

            logger.info(f"âœ… Analysis completed successfully. Retrieved {len(results)} papers")

            return results

        except Exception as e:
            logger.error(f"Error in literature analysis: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    async def _llm_interaction_round_1(self, user_message: str) -> str:
        """ç¬¬ä¸€è½®äº¤äº’ï¼šä¸»é¢˜æ‰©å†™"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # ä»é…ç½®è¯»å–ç³»ç»Ÿæç¤º
        prompts = self.env_config.get("prompts", {})
        system_prompt = prompts.get("analyse_topic_expansion",
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶åˆ†æä¸“å®¶ã€‚ç”¨æˆ·ä¼šç»™ä½ ä¸€ä¸ªç ”ç©¶ä¸»é¢˜ï¼Œè¯·ä½ æ‰©å†™è¿™ä¸ªä¸»é¢˜ï¼Œæä¾›è¯¦ç»†çš„ç ”ç©¶æè¿°ã€‚\n\nè¯·ä»å¤šä¸ªè§’åº¦è¿›è¡Œåˆ†æï¼Œç”Ÿæˆä¸€æ®µä¸“ä¸šä¸”å…¨é¢çš„æè¿°ï¼Œè¿™ä¸ªæè¿°å°†ç”¨äºåç»­çš„æ–‡çŒ®æœç´¢ã€‚\n\nåªè¿”å›æ‰©å†™åçš„ä¸»é¢˜æè¿°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚")

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": system_prompt}
        ] + self.conversation_history

        # è°ƒç”¨LLM
        response = await self.llm_wrapper.async_request(messages)

        # æ·»åŠ assistantå“åº”åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "assistant",
            "content": response
        })

        return response







    def _save_results_to_json(self, results: List[Dict[str, Any]], topic: str) -> str:
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        try:
            # åˆ›å»ºtestç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            test_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'test')
            os.makedirs(test_dir, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³å’Œä¸»é¢˜ï¼‰
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            safe_topic = "".join(c for c in topic if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_topic = safe_topic.replace(' ', '_')[:50]  # é™åˆ¶é•¿åº¦
            filename = f"literature_results_{safe_topic}_{timestamp}.json"
            filepath = os.path.join(test_dir, filename)

            # å‡†å¤‡ä¿å­˜çš„æ•°æ®
            save_data = {
                "topic": topic,
                "timestamp": timestamp,
                "total_results": len(results),
                "results": results,
                "metadata": {
                    "generated_by": "analyse.py",
                    "version": "1.0",
                    "description": f"Literature search results for topic: {topic}"
                }
            }

            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            return filepath

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶å¤±è´¥: {e}")
            return ""

    def _load_config(self):
        try:
            if self.config_path and os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
            else:
                self.config = {
                    "search": {
                        "default_top_n": 20,
                        "default_engine": "google",
                        "similarity_threshold": 80
                    },
                    "interaction": {
                        "timeout_seconds": 0,  # æ— è¶…æ—¶é™åˆ¶
                        "auto_continue": False
                    }
                }
            logger.info("Configuration loaded successfully")
        except Exception as e:
            logger.warning(f"Failed to load config, using defaults: {e}")
            self.config = {}



    def _parse_json_response(self, response: str) -> Optional[Dict[str, Any]]:
        try:
            if response.strip().startswith('{'):
                return json.loads(response.strip())

            import re
            json_pattern = r'```json\s*(.*?)\s*```'
            match = re.search(json_pattern, response, re.DOTALL)
            if match:
                return json.loads(match.group(1).strip())

            brace_pattern = r'\{.*\}'
            match = re.search(brace_pattern, response, re.DOTALL)
            if match:
                return json.loads(match.group(0))

            return None

        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse JSON response: {e}")
            return None

    def _create_task_directory(self, task: str) -> Path:

        safe_task_name = "".join(c for c in task if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_task_name = safe_task_name.replace(' ', '_')

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        task_dir_name = f"{safe_task_name}_{timestamp}"

        task_dir = self.base_dir / task_dir_name
        task_dir.mkdir(parents=True, exist_ok=True)
        (task_dir / "papers").mkdir(exist_ok=True)
        (task_dir / "analysis").mkdir(exist_ok=True)
        (task_dir / "logs").mkdir(exist_ok=True)

        return task_dir
    
    async def _interactive_refinement(self, expanded_topic: Dict[str, Any]) -> Dict[str, Any]:
        logger.info(f"Starting interactive refinement (max {self.max_interaction_rounds} rounds)")

        current_analysis = expanded_topic.copy()

        for round_num in range(self.max_interaction_rounds):
            logger.info(f"--- Interaction Round {round_num + 1}/{self.max_interaction_rounds} ---")

            self._display_analysis(current_analysis, round_num + 1)

            user_feedback = self._get_user_feedback(round_num + 1)

            if user_feedback.get('satisfied', False):
                logger.info("User satisfied with current analysis, proceeding to literature search")
                break

            if user_feedback.get('feedback_text'):
                logger.info("Refining analysis based on user feedback")
                current_analysis = await self._refine_with_feedback(current_analysis, user_feedback)
            else:
                logger.info("No specific feedback provided, keeping current analysis")

        logger.info("Interactive refinement completed")
        return current_analysis

    def _display_analysis(self, analysis: Dict[str, Any], round_num: int):
        """å±•ç¤ºå½“å‰åˆ†æç»“æœç»™ç”¨æˆ·"""
        print(f"\n{'='*60}")
        print(f"ç¬¬ {round_num} è½®åˆ†æç»“æœ")
        print(f"{'='*60}")
        print(f"\nğŸ¯ æˆ‘å¯¹è¿™ä¸ªtopicçš„åˆ†æç»“æœå¦‚ä¸‹ï¼š{analysis.get('description', 'N/A')}")
        

    def _get_user_feedback(self, round_num: int) -> Dict[str, Any]:
        print(f"\n{'='*60}")
        print(f"è¯·æä¾›ç¬¬ {round_num} è½®åé¦ˆ")
        print(f"{'='*60}")

        try:
            satisfied_input = input("\næ‚¨æ˜¯å¦æ»¡æ„å½“å‰çš„åˆ†æç»“æœï¼Ÿ(y/n/å›è½¦ç»§ç»­): ").strip().lower()

            if satisfied_input in ['y', 'yes', 'æ˜¯', 'ok']:
                return {'satisfied': True}

            if satisfied_input in ['', 'continue', 'ç»§ç»­']:
                if round_num >= self.max_interaction_rounds:
                    return {'satisfied': True}
                else:
                    return {'satisfied': False}

            # è·å–å…·ä½“åé¦ˆ
            print("\nè¯·æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®")
            # print("- éœ€è¦è°ƒæ•´çš„æ¦‚å¿µå®šä¹‰")
            # print("- éœ€è¦æ·»åŠ æˆ–åˆ é™¤çš„å­é¢†åŸŸ")
            # print("- éœ€è¦è¡¥å……çš„ç ”ç©¶é—®é¢˜")
            # print("- å…¶ä»–ä»»ä½•æ”¹è¿›æ„è§")
            # print("\nè¾“å…¥æ‚¨çš„åé¦ˆï¼ˆå›è½¦ç»“æŸï¼‰ï¼š")

            feedback_text = input().strip()

            return {
                'satisfied': False,
                'feedback_text': feedback_text,
                'round': round_num
            }

        except KeyboardInterrupt:
            logger.info("User interrupted, proceeding with current analysis")
            return {'satisfied': True}
        except Exception as e:
            logger.warning(f"Error getting user feedback: {e}")
            return {'satisfied': True}





async def analyse(task: str, description: Optional[str] = None, top_n: int = 20) -> List[Dict[str, Any]]:
    analyser = AnalyseInterface()
    return await analyser.analyse(task, description, top_n)


if __name__ == "__main__":
    import sys

    topic = sys.argv[1]
    description = sys.argv[2] if len(sys.argv) > 2 else None
    top_n = int(sys.argv[3]) if len(sys.argv) > 3 else 20

    print(f"ğŸ” å¼€å§‹åˆ†æä¸»é¢˜: {topic}")
    if description:
        print(f"ğŸ“ æè¿°: {description}")
    print(f"ğŸ¯ ç›®æ ‡æ–‡çŒ®æ•°é‡: {top_n}")
    print("-" * 50)

    try:
        import asyncio
        literature_results = asyncio.run(analyse(topic, description, top_n))
        print(f"\nâœ… åˆ†æå®Œæˆï¼æ£€ç´¢åˆ° {len(literature_results)} ç¯‡æ–‡çŒ®")
        print("ğŸ“ æ–‡çŒ®å·²ä¿å­˜åœ¨ llm_search_server æŒ‡å®šçš„ç›®å½•ä¸­")
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
